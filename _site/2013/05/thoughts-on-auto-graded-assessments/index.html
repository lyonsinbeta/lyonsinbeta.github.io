<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Thoughts On Auto-Graded Assessments</title>
    <meta name="viewport" content="width=device-width">
    <meta name="description" content="">
    <link rel="canonical" href="http://lyonsinbeta.com/2013/05/thoughts-on-auto-graded-assessments/">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/main.css">
    <link rel="stylesheet" href="/css/font-awesome.min.css">
</head>


    <body>

    <header class="site-header">

  <div class="wrap">

    <a class="site-title" href="/">The Blog of David Lyons</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <i class="fa fa-lg fa-bars"></i>
      </a>
      <div class="trigger">
        
          
        
          <a class="page-link" href="/about/">About</a>
        
          
        
          
        
        <a class="page-link" href="/rss.xml"><i class="fa fa-lg fa-rss"></i></a>
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrap">
      <div class="post">

  <header class="post-header">
    <h1>Thoughts On Auto-Graded Assessments</h1>
    <!-- <p class="meta">2013-05-06</p> -->
  </header>

  <article class="post-content">
  <p>All of the major Learning Management Systems have some sort of assessment tool. It’s a staple of traditional education to, at some point during a class, present students with a list of roughly 25 multiple choice questions to evaluate their mastery of the material. In the bad old days these had to be marked by hand, then later educators were blessed (and students were cursed) by scantrons that could be graded by machine, and for the last decade and a half computer based assessments have become very popular.</p>

<p>Computer based assessments have all of the perks of paper multiple choice tests; easy to grade, familiar format, uniform, as well as the central perk of scantrons; automatic grading, and they have the added bonus of not wasting paper! Another amazing benefit is decentralized delivery, students don’t have to be present to take an assessment.</p>

<p>What I find odd is the main complaint against auto-graded, computer based, assessments is how easy it is to cheat. “Students can use their notes,” faculty cry out, “and how do we even know who is really taking the assessment?!” These are legitimate concerns, and quelling them has created an entire industry of remote proctoring (which I believe is effective) and anti-cheating software (which I know is ineffective). I think the solution isn’t Orwellian monitoring of student activities, but to reconsider how auto-graded assessments are utilized.</p>

<p>Let’s assume for some reason you can’t give up auto-graded assessments and go to a completely assignment/project based grading scheme; how can you more effectively use auto-graded assessments? A typical course is comprised of a large number of low-value assignments and a small number of high-value assessments. Instead, consider a large number of short, open note (yes, seriously), low-value quizzes, and a few high-value assignments/projects. With this model you encourage frequent review of course content, and can make it even more frequent by allowing students multiple attempts. Making quizzes open note encourages review of notes and course texts. For the instructor it keeps the amount of hand graded work to a manageable level, which can be critical in ever larger and larger courses. It also takes the stigma off of out of class, unproctored, assessment; in an online course it’s crucial that students can be assessed remotely, but in hybrid and face to face courses it frees up classroom time for group work, labs, or other projects by making quizzes an outside class assignment.</p>

<p>The above model won’t work for every course, and it’s far from the only alternative assessment model, but the notion of removing some of the prestige from assessments and placing it instead on assignments/projects is worth considering. Online and time-shifted assessments are a very convenient tool for instructors but it requires a shift in thinking as well. Long gone are the days of standing in front of the blackboard while students carefully circle letters or fill in bubbles. The improvement in technology isn’t just an opportunity to save time and paper, but an opportunity to rethink how we assess student learning.</p>

  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrap">

    <h2 class="footer-heading">Thanks for stopping by</h2>

    <div class="footer-col-1 column">
      <ul>
        <li>I think you're great.</li>
      </ul>
    </div>

    <div class="footer-col-2 column">
      <ul class="fa-ul">
        <li><i class="fa-li fa fa-lg fa-github-alt"></i>
          <a href="https://github.com/lyonsinbeta">
            <span class="username">lyonsinbeta</span>
          </a>
        </li>
        <li><i class="fa-li fa fa-lg fa-twitter"></i>
          <a href="https://twitter.com/lyonsinbeta">
            <span class="username">lyonsinbeta</span>
          </a>
        </li>
        <li><i class="fa-li fa fa-lg fa-google-plus-square"></i>
          <a href="https://plus.google.com/+DavidLyons">
            <span class="username">DavidLyons</span>
          </a>
        </li>
        <li><i class="fa-li fa fa-lg fa-microphone"></i><a href="http://sunriserobot.net">Sunrise Robot</a></li>
      </ul>
    </div>

    <div class="footer-col-3 column">
      <p class="text"></p>
    </div>

  </div>

</footer>

    <script src="/js/easter-egg.js"></script>
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-44733266-1', 'auto');
  ga('send', 'pageview');

</script>
    </body>
</html>
